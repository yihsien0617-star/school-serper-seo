# æª”æ¡ˆåç¨±ï¼š2_dashboard.py (Serper çœŸå¯¦æ•¸æ“šç‰ˆ)
import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json

# ==========================================
# ğŸ”‘ è«‹å°‡ä½ åœ¨ serper.dev ç”³è«‹çš„ API Key è²¼åœ¨ä¸‹æ–¹
SERPER_API_KEY = "6dcb4225919e50e501bbddfab3411337b99c0547" 
# ==========================================

st.set_page_config(page_title="å­¸æ ¡æ‹›ç”Ÿ SEO æˆ°æƒ…å®¤ (çœŸå¯¦æ•¸æ“šç‰ˆ)", layout="wide")

# è®€å–æ•¸æ“š
try:
    df = pd.read_csv('school_data.csv')
except FileNotFoundError:
    st.error("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° school_data.csvï¼Œè«‹ç¢ºèªæœ‰å°‡ csv æª”ä¸Šå‚³åˆ° GitHubã€‚")
    st.stop()

st.sidebar.title("ğŸ« æ‹›ç”Ÿç­–ç•¥æ§åˆ¶å°")
st.sidebar.caption("è³‡æ–™ä¾†æºï¼šGoogle (via Serper)")
dept_list = ["å…¨æ ¡ç¸½è¦½"] + list(df['Department'].unique())
selected_dept = st.sidebar.selectbox("é¸æ“‡åˆ†æè¦–è§’", dept_list)

# --- æ ¸å¿ƒåŠŸèƒ½ï¼šSerper API æœå°‹ (æ¥­ç•Œæ¨™æº–) ---
def get_google_results(keyword):
    """
    é€é Serper API å–å¾— 100% çœŸå¯¦çš„ Google æœå°‹çµæœã€‚
    é€™æ˜¯ç›®å‰æœ€ç©©å®šã€æœ€ä¸æœƒè¢«æ“‹çš„é›²ç«¯è§£æ±ºæ–¹æ¡ˆã€‚
    """
    url = "https://google.serper.dev/search"
    
    # è¨­å®šæœå°‹åƒæ•¸ï¼šåœ°å€(tw), èªè¨€(zh-tw)
    payload = json.dumps({
        "q": keyword,
        "gl": "tw",
        "hl": "zh-tw",
        "num": 3 # åªæŠ“å‰ 3 å
    })
    
    headers = {
        'X-API-KEY': SERPER_API_KEY,
        'Content-Type': 'application/json'
    }

    try:
        response = requests.post(url, headers=headers, data=payload)
        
        # æª¢æŸ¥ API Key æ˜¯å¦æ­£ç¢º
        if response.status_code == 403:
            return [], "âŒ API Key éŒ¯èª¤æˆ–é¡åº¦ä¸è¶³ï¼Œè«‹æª¢æŸ¥ serper.dev"
            
        data = response.json()
        
        # è§£æå›å‚³çš„ JSON è³‡æ–™
        if "organic" in data:
            results = []
            for item in data["organic"]:
                results.append({
                    "title": item.get("title"),
                    "href": item.get("link"),
                    "snippet": item.get("snippet", "ç„¡é è¦½æ–‡å­—")
                })
            return results, "ğŸŸ¢ Google çœŸå¯¦æ•¸æ“š (Live)"
        else:
            return [], "âš ï¸ Google æŸ¥ç„¡è³‡æ–™"
            
    except Exception as e:
        return [], f"é€£ç·šéŒ¯èª¤: {str(e)}"

# --- ä¸»ç•«é¢é¡¯ç¤º ---

if selected_dept == "å…¨æ ¡ç¸½è¦½":
    st.title("ğŸ“Š å…¨æ ¡ç§‘ç³»ç¶²è·¯è²é‡ç¸½è¦½")
    
    total = df['Search_Volume'].sum()
    top = df.groupby('Department')['Search_Volume'].sum().idxmax()
    col1, col2 = st.columns(2)
    col1.metric("å…¨æ ¡ç¸½æ½›åœ¨æœå°‹æµé‡", f"{total:,}")
    col2.metric("ç¶²è·¯è²é‡å† è»", top)
    st.markdown("---")
    
    dept_traffic = df.groupby('Department')['Search_Volume'].sum().reset_index().sort_values('Search_Volume', ascending=False)
    fig_bar = px.bar(dept_traffic, x='Department', y='Search_Volume', color='Department')
    st.plotly_chart(fig_bar, width="stretch")

else:
    st.title(f"ğŸ” {selected_dept}ï¼šæ‹›ç”Ÿé—œéµå­—åˆ†æ")
    dept_df = df[df['Department'] == selected_dept]
    best_keyword = dept_df.sort_values('Opportunity_Score', ascending=False).iloc[0]
    
    col1, col2 = st.columns(2)
    col1.metric("ğŸ”¥ å¿…å¯«æ–‡ç« ä¸»é¡Œ", best_keyword['Keyword'])
    col2.metric("å¹³å‡æœˆæœå°‹é‡", f"{int(dept_df['Search_Volume'].mean()):,}")
    
    st.divider()

    # --- çœŸå¯¦æœå°‹å€ ---
    st.subheader("ğŸ•µï¸ ç«¶çˆ­å°æ‰‹åˆ†æ (Google çœŸå¯¦æ’å)")
    st.info("æ­¤åŠŸèƒ½ä¸²æ¥ Serper SEO è³‡æ–™åº«ï¼Œé¡¯ç¤ºç•¶ä¸‹çœŸå¯¦çš„ Google æ’åã€‚")
    
    col_s1, col_s2 = st.columns([3, 1])
    with col_s1:
        target_kw = st.selectbox("é¸æ“‡é—œéµå­—ï¼š", dept_df['Keyword'].unique())
    with col_s2:
        st.write("") 
        st.write("") 
        btn = st.button("é–‹å§‹åˆ†æ", type="primary")

    if btn:
        # æª¢æŸ¥ä½¿ç”¨è€…æœ‰æ²’æœ‰å¿˜è¨˜å¡« Key
        if "é€™è£¡è²¼ä¸Š" in SERPER_API_KEY:
            st.error("âš ï¸ è«‹å…ˆåœ¨ç¨‹å¼ç¢¼ä¸­å¡«å…¥ Serper API Keyï¼")
        else:
            with st.spinner(f"æ­£åœ¨å‘ Google è«‹æ±‚ã€Œ{target_kw}ã€çš„çœŸå¯¦æ•¸æ“š..."):
                results, status = get_google_results(target_kw)
                
                if "éŒ¯èª¤" in status:
                    st.error(status)
                else:
                    st.success(f"âœ… åˆ†æå®Œæˆï¼ä¾†æºï¼š{status}")

                    for i, res in enumerate(results):
                        title = res.get('title', 'ç„¡æ¨™é¡Œ')
                        url = res.get('href', '#')
                        snippet = res.get('snippet', '')
                        
                        # æ™ºæ…§åˆ†é¡æ¨™ç±¤
                        icon = "ğŸ”—"
                        tag = "ä¸€èˆ¬ç¶²ç«™"
                        
                        if "dcard" in url: 
                            icon = "ğŸ’¬"; tag = "Dcard"
                        elif "ptt" in url: 
                            icon = "ğŸ’¬"; tag = "PTT"
                        elif "104" in url or "1111" in url: 
                            icon = "ğŸ’¼"; tag = "äººåŠ›éŠ€è¡Œ"
                        elif "hwai" in url: 
                            icon = "ğŸ†"; tag = "æœ¬æ ¡å®˜ç¶²"
                        elif "edu.tw" in url: 
                            icon = "âš”ï¸"; tag = "ä»–æ ¡ç«¶çˆ­è€…"

                        with st.expander(f"ç¬¬ {i+1} åï¼š{icon} {tag} - {title}", expanded=True):
                            st.markdown(f"**é€£çµï¼š** [{url}]({url})")
                            st.caption(f"ğŸ“ å…§æ–‡æ‘˜è¦ï¼š{snippet}")
                            
                            # çµ¦ç³»ä¸»ä»»çš„å»ºè­°
                            if tag == "Dcard" or tag == "PTT":
                                st.info("ğŸ’¡ å»ºè­°ï¼šæ­¤ç‚ºç¤¾ç¾¤è¨è«–ï¼Œè«‹å¯†åˆ‡é—œæ³¨å­¸ç”Ÿè©•åƒ¹ï¼Œå¿…è¦æ™‚å®‰æ’å›æ–‡ã€‚")
                            elif tag == "ä»–æ ¡ç«¶çˆ­è€…":
                                st.error("ğŸ’¡ å»ºè­°ï¼šç«¶çˆ­å°æ‰‹æ’ååœ¨æˆ‘å€‘å‰é¢ï¼è«‹åˆ†æå°æ–¹ç¶²é å…§å®¹ï¼Œå„ªåŒ–æˆ‘å€‘çš„é—œéµå­—ã€‚")

    st.divider()
    
    st.subheader("ğŸ“ å„ªå…ˆæ’°å¯«å»ºè­°")
    st.dataframe(
        dept_df[['Keyword', 'Search_Volume', 'Opportunity_Score']]
        .sort_values('Opportunity_Score', ascending=False)
        .style.background_gradient(subset=['Opportunity_Score'], cmap="Greens"),
        width="stretch"
    )
# é€™åªæ˜¯ä¸€å€‹æ¦‚å¿µç¯„ä¾‹
import google.generativeai as genai

def generate_article(keyword):
    prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„å¤§å­¸æ‹›ç”Ÿè¡ŒéŠ·å°ˆå®¶ã€‚
    è«‹é‡å°é—œéµå­—ã€Œ{keyword}ã€ï¼Œç‚ºä¸­è¯é†«äº‹ç§‘æŠ€å¤§å­¸é†«å­¸æª¢é©—ç”Ÿç‰©æŠ€è¡“ç³»ï¼Œ
    æ’°å¯«ä¸€ç¯‡ 500 å­—çš„éƒ¨è½æ ¼æ–‡ç« ã€‚
    
    æ–‡ç« è¦æ±‚ï¼š
    1. èªæ°£è¦ªåˆ‡ï¼Œé‡å°é«˜ä¸­ç”Ÿèˆ‡å®¶é•·ã€‚
    2. å¿…é ˆæåˆ°æœ¬ç³»çš„å„ªå‹¢ï¼ˆå¦‚ï¼šåœ‹è€ƒé€šéç‡é«˜ã€è¨­å‚™æ–°ï¼‰ã€‚
    3. åŒ…å« 3 å€‹å¸¸è¦‹å•ç­” (FAQ)ã€‚
    """
    model = genai.GenerativeModel('gemini-pro')
    response = model.generate_content(prompt)
    return response.text
