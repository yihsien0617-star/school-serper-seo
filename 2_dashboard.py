# æª”æ¡ˆåç¨±ï¼š2_dashboard.py (è‡ªæˆ‘è¨ºæ–·ç‰ˆ)
import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
import google.generativeai as genai

# ==========================================
# ğŸ”‘ è¨­å®šå€ (è«‹åœ¨æ­¤å¡«å…¥æ‚¨çš„ API Key)
# ==========================================
SERPER_API_KEY = "6dcb4225919e50e501bbddfab3411337b99c0547"
GEMINI_API_KEY = "AIzaSyCU62-XBvqOsH3Dq3jvote9jd6jMew79Qk"
# ==========================================

# è¨­å®š AI
if "ä½ çš„" not in GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

st.set_page_config(page_title="å­¸æ ¡æ‹›ç”Ÿ SEO æˆ°æƒ…å®¤", layout="wide")

# è®€å–æ•¸æ“š
try:
    df = pd.read_csv('school_data.csv')
except FileNotFoundError:
    st.error("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° school_data.csvã€‚")
    st.stop()

st.sidebar.title("ğŸ« æ‹›ç”Ÿç­–ç•¥æ§åˆ¶å°")
st.sidebar.caption("ç³»çµ±æ ¸å¿ƒï¼šGemini (è‡ªå‹•åµæ¸¬)")
dept_list = ["å…¨æ ¡ç¸½è¦½"] + list(df['Department'].unique())
selected_dept = st.sidebar.selectbox("é¸æ“‡åˆ†æè¦–è§’", dept_list)

# --- å‡½æ•¸ 1: Serper çœŸå¯¦æœå°‹ ---
def get_google_results(keyword):
    url = "https://google.serper.dev/search"
    payload = json.dumps({"q": keyword, "gl": "tw", "hl": "zh-tw", "num": 3})
    headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=payload)
        data = response.json()
        if "organic" in data:
            return data["organic"], "ğŸŸ¢ Google çœŸå¯¦æ•¸æ“š"
        else:
            return [], "âš ï¸ æŸ¥ç„¡è³‡æ–™"
    except Exception as e:
        return [], f"é€£ç·šéŒ¯èª¤: {str(e)}"

# --- å‡½æ•¸ 2: Gemini AI å¯«æ–‡ç«  (å«è‡ªå‹•è¨ºæ–·) ---
def generate_ai_article(keyword, department):
    prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„å¤§å­¸æ‹›ç”Ÿè¡ŒéŠ·å°ˆå®¶ã€‚
    è«‹é‡å°é—œéµå­—ã€Œ{keyword}ã€ï¼Œç‚ºã€Œ{department}ã€æ’°å¯«ä¸€ç¯‡éƒ¨è½æ ¼æ–‡ç« è‰ç¨¿ã€‚
    å­—æ•¸ï¼šç´„ 600 å­—ã€‚
    """
    
    try:
        # 1. å…ˆå˜—è©¦æœ€æ–°çš„ Flash æ¨¡å‹
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        error_msg = str(e)
        
        # 2. å¦‚æœå¤±æ•—ï¼Œå˜—è©¦åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹ (Debug æ¨¡å¼)
        if "404" in error_msg or "not found" in error_msg:
            try:
                available_models = []
                for m in genai.list_models():
                    if 'generateContent' in m.supported_generation_methods:
                        available_models.append(m.name)
                
                # å›å‚³è¨ºæ–·è¨Šæ¯
                return f"""
                âŒ AI æ¨¡å‹åç¨±éŒ¯èª¤ (404)ã€‚
                
                ğŸ” **ç³»çµ±è‡ªæˆ‘è¨ºæ–·ï¼š**
                æ‚¨çš„ API Key ç›®å‰å¯ç”¨çš„æ¨¡å‹åªæœ‰é€™äº›ï¼š
                {', '.join(available_models)}
                
                ğŸ‘‰ è«‹è¨˜ä¸‹ä¸Šé¢ä»¥ 'models/' é–‹é ­çš„åç¨± (ä¾‹å¦‚ models/gemini-pro)ï¼Œ
                ç„¶å¾Œå‘Šè¨´å·¥ç¨‹å¸«ä¿®æ”¹ç¨‹å¼ç¢¼ã€‚
                """
            except Exception as debug_e:
                return f"âŒ åš´é‡éŒ¯èª¤ï¼šé€£åˆ—å‡ºæ¨¡å‹éƒ½å¤±æ•—ã€‚åŸå› ï¼š{str(debug_e)}\nåŸå§‹éŒ¯èª¤ï¼š{error_msg}"
        
        return f"âŒ AI ç”Ÿæˆå¤±æ•—: {error_msg}"

# --- ä¸»ç•«é¢é‚è¼¯ ---

if selected_dept == "å…¨æ ¡ç¸½è¦½":
    st.title("ğŸ“Š å…¨æ ¡ç§‘ç³»ç¶²è·¯è²é‡ç¸½è¦½")
    total = df['Search_Volume'].sum()
    top = df.groupby('Department')['Search_Volume'].sum().idxmax()
    col1, col2 = st.columns(2)
    col1.metric("å…¨æ ¡ç¸½æ½›åœ¨æœå°‹æµé‡", f"{total:,}")
    col2.metric("ç¶²è·¯è²é‡å† è»", top)
    st.markdown("---")
    dept_traffic = df.groupby('Department')['Search_Volume'].sum().reset_index().sort_values('Search_Volume', ascending=False)
    fig_bar = px.bar(dept_traffic, x='Department', y='Search_Volume', color='Department')
    st.plotly_chart(fig_bar, width="stretch")

else:
    st.title(f"ğŸ” {selected_dept}ï¼šæ‹›ç”Ÿé—œéµå­—åˆ†æ")
    dept_df = df[df['Department'] == selected_dept]
    if dept_df.empty: st.stop()
    best_keyword = dept_df.sort_values('Opportunity_Score', ascending=False).iloc[0]
    
    col1, col2 = st.columns(2)
    col1.metric("ğŸ”¥ å¿…å¯«æ–‡ç« ä¸»é¡Œ", best_keyword['Keyword'])
    col2.metric("å¹³å‡æœˆæœå°‹é‡", f"{int(dept_df['Search_Volume'].mean()):,}")
    st.divider()

    st.subheader("ğŸ•µï¸ ç«¶çˆ­å°æ‰‹åµæŸ¥ & âœ¨ AI æ–‡æ¡ˆç”Ÿæˆ")
    target_kw = st.selectbox("ğŸ‘‡ ç¬¬ä¸€æ­¥ï¼šè«‹é¸æ“‡æ‚¨æƒ³é€²æ”»çš„é—œéµå­—", dept_df['Keyword'].unique())
    st.write("") 
    btn = st.button("ğŸš€ ç¬¬äºŒæ­¥ï¼šé»æˆ‘é–‹å§‹åˆ†æ + ç”Ÿæˆæ–‡ç« ", type="primary", use_container_width=True)

    if btn:
        if "ä½ çš„" in GEMINI_API_KEY or "ä½ çš„" in SERPER_API_KEY:
             st.error("âš ï¸ è«‹å…ˆåœ¨ç¨‹å¼ç¢¼ä¸­å¡«å…¥æ­£ç¢ºçš„ API Keyï¼")
        else:
            with st.spinner(f"æ­£åœ¨åˆ†æã€Œ{target_kw}ã€çš„ Google æ’å..."):
                results, status = get_google_results(target_kw)
                if "éŒ¯èª¤" in status: st.error(status)
                else:
                    st.success(f"âœ… æœå°‹å®Œæˆï¼({status})")
                    with st.expander("ğŸ”» ç«¶çˆ­å°æ‰‹åˆ—è¡¨", expanded=True):
                        for i, res in enumerate(results):
                            st.markdown(f"**{i+1}. [{res.get('title')}]({res.get('link')})**")

            st.markdown("---")
            st.subheader(f"âœ¨ AI ç‚ºæ‚¨ç”Ÿæˆçš„ã€Œ{target_kw}ã€æ–‡ç« è‰ç¨¿")
            
            with st.spinner("ğŸ¤– AI æ­£åœ¨å˜—è©¦å¯«ä½œ (è‹¥å¤±æ•—å°‡å•Ÿå‹•è‡ªæˆ‘è¨ºæ–·)..."):
                ai_article = generate_ai_article(target_kw, selected_dept)
                
                # å¦‚æœæ˜¯è¨ºæ–·è¨Šæ¯ï¼Œé¡¯ç¤ºç‚ºé»ƒè‰²è­¦å‘Š
                if "âŒ" in ai_article:
                    st.warning(ai_article)
                else:
                    st.markdown(ai_article)
                    st.download_button("ğŸ“¥ ä¸‹è¼‰æ–‡ç«  (.txt)", ai_article, f"{target_kw}.txt")

    st.divider()
    clean_df = dept_df[['Keyword', 'Search_Volume', 'Competition_Level', 'Opportunity_Score']].sort_values('Opportunity_Score', ascending=False)
    st.dataframe(clean_df, use_container_width=True)
